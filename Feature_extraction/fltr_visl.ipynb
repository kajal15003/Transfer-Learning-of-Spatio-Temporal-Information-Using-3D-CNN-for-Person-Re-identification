{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Make sure that caffe is on the python path:\n",
    "caffe_root = '../'  # this file is expected to be in {caffe_root}/examples\n",
    "import sys\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "import caffe\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = caffe.Classifier(caffe_root + 'examples/imagenet/imagenet_deploy.prototxt',\n",
    "                       caffe_root + 'examples/imagenet/caffe_reference_imagenet_model')\n",
    "net.set_phase_test()\n",
    "net.set_mode_cpu()\n",
    "# input preprocessing: 'data' is the name of the input blob == net.inputs[0]\n",
    "net.set_mean('data', caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')  # ImageNet mean\n",
    "net.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB\n",
    "net.set_input_scale('data', 255)  # the reference model operates on images in [0,255] range instead of [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = net.predict([caffe.io.load_image(caffe_root + 'examples/images/cat.jpg')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[(k, v.data.shape) for k, v in net.blobs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[(k, v[0].data.shape) for k, v in net.params.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our network takes BGR images, so we need to switch color channels\n",
    "def showimage(im):\n",
    "    if im.ndim == 3:\n",
    "        im = im[:, :, ::-1]\n",
    "    plt.imshow(im)\n",
    "    \n",
    "# take an array of shape (n, height, width) or (n, height, width, channels)\n",
    "#  and visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)\n",
    "def vis_square(data, padsize=1, padval=0):\n",
    "    data -= data.min()\n",
    "    data /= data.max()\n",
    "    \n",
    "    # force the number of filters to be square\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, padsize), (0, padsize)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant', constant_values=(padval, padval))\n",
    "    \n",
    "    # tile the filters into an image\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    \n",
    "    showimage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# index four is the center crop\n",
    "image = net.blobs['data'].data[4].copy()\n",
    "image -= image.min()\n",
    "image /= image.max()\n",
    "showimage(image.transpose(1, 2, 0))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
